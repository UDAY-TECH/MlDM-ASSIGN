# -*- coding: utf-8 -*-
"""MLDM assign-8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i17uLkc7_x63Oc0zQ58ywMGtCWDqQJiC
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder,OneHotEncoder

data = pd.read_csv('/content/WA_Fn-UseC_-HR-Employee-Attrition.csv')
data.head()

le = LabelEncoder()
change = ['Department','BusinessTravel','Attrition','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']

for x in change:
  data[x] = le.fit_transform(data[x])

data.head()

data.isna().sum()

counts = data['Attrition'].value_counts().to_dict()

plt.bar(counts.keys(),counts.values())
plt.title('Target value counts')
plt.xticks([0,1])
plt.show()

data.drop(['Over18','EmployeeNumber','EmployeeCount','StandardHours'],axis=1,inplace=True)

#For categorical variables 
#Distribution plots

fig,ax = plt.subplots(3,3, figsize=(14,14))
sns.distplot(data['TotalWorkingYears'], ax = ax[0,0]) 
sns.distplot(data['YearsAtCompany'], ax = ax[0,1]) 
sns.distplot(data['DistanceFromHome'], ax = ax[0,2]) 
sns.distplot(data['YearsInCurrentRole'], ax = ax[1,0]) 
sns.distplot(data['YearsWithCurrManager'], ax = ax[1,1]) 
sns.distplot(data['YearsSinceLastPromotion'], ax = ax[1,2]) 
sns.distplot(data['PercentSalaryHike'], ax = ax[2,0]) 
sns.distplot(data['YearsSinceLastPromotion'], ax = ax[2,1]) 
sns.distplot(data['TrainingTimesLastYear'], ax = ax[2,2]) 
plt.show()

feats = ["Gender","MaritalStatus","WorkLifeBalance","EnvironmentSatisfaction","JobSatisfaction","JobLevel","BusinessTravel",'Department','EducationField','OverTime']

x = plt.figure(figsize=(18,18))
for i,j in enumerate(feats,1):
  plt.subplot(5,2,i)
  sns.countplot(data=data,x=j,hue='Attrition')
  plt.xticks( rotation=90)

plt.show()

#Breakdown of Distance from home by JobLevel and Attrition

sns.barplot(data=data,x='Attrition',y='DistanceFromHome',hue='JobLevel')
plt.show()

#Breakdown of average monthly income by education and attrition

sns.barplot(data=data,x='Attrition',y='MonthlyIncome',hue='Education')
plt.show()

correlation = data.corr()

ax = plt.figure(figsize=(20,12))
sns.heatmap(correlation,annot=True)
plt.show()

cols = data.columns
formula = 'Attrition ~ '
for x in cols:
  if(x=='Attrition'):
    continue
  formula = formula + x + ' + '
formula = formula[:-2]
print(formula)

from statsmodels.stats.outliers_influence import variance_inflation_factor
from patsy import dmatrices

yvar, Xvar = dmatrices(formula, data, return_type='dataframe')

# For each Xvar, calculate VIF and save in dataframe
vif = pd.DataFrame()
vif["VIF"] = [variance_inflation_factor(Xvar.values, i) for i in range(Xvar.shape[1])]
vif["Predictors"] = Xvar.columns
vif.round(3)

#dropping columns based on correlation matrix and VIF Factors 

cols = ['YearsWithCurrManager','YearsAtCompany','TotalWorkingYears','PerformanceRating','MonthlyIncome','StockOptionLevel','JobRole','JobLevel']
data.drop(cols,axis=1,inplace=True)

from sklearn.model_selection import train_test_split

train,test = train_test_split(data,test_size=0.25,random_state=42)

print(train.shape,test.shape)

y_train = train['Attrition']
x_train = train.drop(['Attrition'],axis=1)

y_test = test['Attrition']
x_test = test.drop(['Attrition'],axis=1)

compare = {}

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,f1_score,precision_score,confusion_matrix
from sklearn.model_selection import GridSearchCV

param_grid = {'n_estimators':[10,50,100,150],'max_depth':[10,50,100,150]}
grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose=0)
grid.fit(x_train,y_train)
print(grid.best_params_)

rf_model = RandomForestClassifier(max_depth=100,n_estimators=10)
rf_model.fit(x_train,y_train)

pred = rf_model.predict(x_test)

acc = accuracy_score(y_test,pred)
f1 = f1_score(y_test,pred)
pscore = precision_score(y_test,pred)

compare['RandomForest']= [acc,f1,pscore]
print('Accuracy_score : ',acc)
print('F1_score : ',f1)
print('Precision_score : ',pscore)
print()
print('ConfusionMatrix : \n',confusion_matrix(y_test,pred,labels=[0,1]))

imps = rf_model.feature_importances_

sns.barplot(x=x_train.columns,y=imps)
plt.xticks(rotation=90)
plt.show()

d = dict(zip(x_train.columns,imps))
imp_df = pd.DataFrame(d.items(),columns=['Feature','Feature Importance'])
print('Feature Importances : \n',imp_df)

from sklearn.svm import SVC

#hyper parameter tuning is taking lot of time for SVC so, it is excluded for this model

svm_model = SVC()
svm_model.fit(x_train,y_train)

pred = svm_model.predict(x_test)

acc = accuracy_score(y_test,pred)
f1 = f1_score(y_test,pred,zero_division=1)
pscore = precision_score(y_test,pred,zero_division=1)

compare['SVM']= [acc,f1,pscore]
print('Accuracy_score : ',acc)
print('F1_score : ',f1)
print('Precision_score : ',pscore)
print()
print('ConfusionMatrix : \n',confusion_matrix(y_test,pred,labels=[0,1]))

from sklearn.tree import DecisionTreeClassifier

#hyperparameter tuning
param_grid = {'criterion':['gini', 'entropy'],
              'max_depth':[5,10,25,50]}

grid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose=0)
grid.fit(x_train,y_train)
print(grid.best_params_)

dt_model = DecisionTreeClassifier(criterion='gini',max_depth=5)
dt_model.fit(x_train,y_train)

pred = dt_model.predict(x_test)

acc = accuracy_score(y_test,pred)
f1 = f1_score(y_test,pred,zero_division=1)
pscore = precision_score(y_test,pred,zero_division=1)

compare['DecisionTree']= [acc,f1,pscore]
print('Accuracy_score : ',acc)
print('F1_score : ',f1)
print('Precision_score : ',pscore)
print()
print('ConfusionMatrix : \n',confusion_matrix(y_test,pred,labels=[0,1]))

from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(x_train,y_train)

pred = nb_model.predict(x_test)

acc = accuracy_score(y_test,pred)
f1 = f1_score(y_test,pred,zero_division=1)
pscore = precision_score(y_test,pred,zero_division=1)

compare['NaiveBayes']= [acc,f1,pscore]
print('Accuracy_score : ',acc)
print('F1_score : ',f1)
print('Precision_score : ',pscore)
print()
print('ConfusionMatrix : \n',confusion_matrix(y_test,pred,labels=[0,1]))

from sklearn.neighbors import KNeighborsClassifier

#hyperparameter tuning
param_grid = {'n_neighbors':[5,10,25,50],'leaf_size':[10,20,30,40],'algorithm':['auto','ball_tree']}

grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, verbose=0)
grid.fit(x_train,y_train)
print(grid.best_params_)

knn_model = KNeighborsClassifier(n_neighbors=25,algorithm='auto',leaf_size=10)
knn_model.fit(x_train,y_train)

pred = knn_model.predict(x_test)

acc = accuracy_score(y_test,pred)
f1 = f1_score(y_test,pred,zero_division=1)
pscore = precision_score(y_test,pred,zero_division=1)

compare['KNearestNeighbors']= [acc,f1,pscore]
print('Accuracy_score : ',acc)
print('F1_score : ',f1)
print('Precision_score : ',pscore)
print()
print('ConfusionMatrix : \n',confusion_matrix(y_test,pred,labels=[0,1]))

compare_df = pd.DataFrame(compare.values(),columns=['Accuracy Score','F1 Score','Precision Score'],index=compare.keys())
print(compare_df)

compare_df.plot(kind='bar',figsize=(10,8))
plt.title('Models Comparision')
plt.xlabel('Models')
plt.ylabel('Scores')
plt.show()